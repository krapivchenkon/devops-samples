---
#####################################################
### Current play contains task to setup proper aws 
### connection:
### - create aws_key_name
### - setup inbound/outbound ACL
#####################################################
- name: SETUP AWS CONNECTION
  hosts: localhost
  tags: setup
  connection: local
  gather_facts: false   
  tasks:
    # Following tasks will create private key file if its missing
    - stat: 
        path: "{{ansible_ssh_private_key_file}}"
      register: aws_pkey
    - name: example ec2 key
      # debug: msg="File missing"
      ec2_key:
        region: '{{ aws_default_region }}'
        name: "{{aws_key_name}}"
      register: aws_ssh_key
      when: aws_pkey.stat.exists == False
    
    # - debug: msg="new key_material {{aws_ssh_key}}."
    - copy:
        content: "{{ aws_ssh_key.key.private_key }}"
        dest: "{{ansible_ssh_private_key_file}}"
        mode: 0600
      when: aws_pkey.stat.exists == False

    # Below task creates ACL rules for default security group
    - name: Create HTTP and HTTPS Security Group
      ec2_group:
        # module: ec2_group
        region: "{{ aws_default_region }}"
        # vpc_id: "{{ vpc }}"
        name: "{{aws_security_group}}"
        description: Security group for HTTP(S) access
        rules:
          - proto: all
            group_name: "{{aws_security_group}}"
          - proto: tcp
            from_port: 80
            to_port: 80
            cidr_ip: 0.0.0.0/0
          - proto: icmp
            from_port: -1 # icmp type, -1 = any type
            to_port:  -1 # icmp subtype, -1 = any subtype
            cidr_ip: 0.0.0.0/0
          - proto: tcp
            from_port: 22
            to_port: 22
            cidr_ip: 0.0.0.0/0
        rules_egress:
          - proto: all
            cidr_ip: 0.0.0.0/0


#####################################################
### Playbook contains tasks for gathering facts 
#####################################################
- name: GATHER FACTS
  hosts: localhost
  connection: local
  gather_facts : false
  tags: [start,stop,term,term_stopped,check,status]
  tasks:
    - name: Gather EC2 facts
      ec2_remote_facts:
        region: '{{ aws_default_region }}'
        filters:
          # instance-state-name: stopped
          "tag:Name": "{{ aws_instance_tag }}"
      register: ec2_info

    - name: Collect facts about ec2 instance state
      set_fact:
        stopped_inst: "{{ ec2_info.instances|selectattr('state','equalto','stopped')|map(attribute='id')|list }}"
        running_inst: "{{ ec2_info.instances|selectattr('state','equalto','running')|map(attribute='id')|list }}"
        all_inst    : "{{ aws_ec2_count }}"
    - debug: msg="Found {{running_inst|count}} running and {{stopped_inst|count}} stopped instances. Required number of running instances is {{all_inst}}."

    - name: Add all instance public DNS to host group ec2
      add_host: hostname={{ item }} groups=ec2
      with_items: "{{ ec2_info.instances|selectattr('state','equalto','running')|map(attribute='public_dns_name')|list }}"
      when: "{{running_inst|count > 0}}"


#####################################################
### Playbook contains tasks for launching instances
#####################################################
- name: LAUNCH
  hosts: localhost
  connection: local
  gather_facts : false
  tags: start
  tasks:
    - set_fact:
        # number of stopped instances that will be started
        stopped_to_start: "{{ stopped_inst|lst_slice(0,all_inst-running_inst|count) }}"
    
    # - debug: msg="Stopped  {{stopped_to_start}}."

    - name: Start stopped instances
      ec2:
        region: '{{ aws_default_region }}'
        instance_ids: "{{stopped_to_start}}"
        state: running
      when: '{{ running_inst|count < all_inst }} and {{stopped_to_start|count > 0}}'
    - debug: msg="Started {{stopped_to_start|count}} instances from existing {{stopped_inst|count}} stopped instances"

    # wait for stopped instances to start to make sure exact_count will work correctly on the next step
    # - name: Wait for SSH to come up on stopped instances
    #   #TODO: public_dns_name isn't available here. we need to re-fetch info from ec2 about this specific ids
    #   wait_for: host={{ item.public_dns_name }} port=22 delay=30 timeout=120 state=started
    #   with_items: '{{ ec2_info.instances }}'
    #   # skip this task if there are no stopped instances to be started
    #   when: "ec2_info.instances is defined and {{stopped_to_start|count > 0}}"

    - name: Start missing ec2 instances
      ec2:
        key_name: "{{ aws_key_name }}"
        group: '{{ aws_security_group }}'
        region: '{{ aws_default_region }}'
        instance_type: '{{ aws_instance_type }}'
        image: '{{ aws_ami_image }}'
        wait: true
        # exact_count: '{{all_inst-running_inst|count-stopped_to_start|count}}'
        exact_count: '{{all_inst}}'
        count_tag: 
          Name: "{{aws_instance_tag}}"
        instance_tags:
          Name: "{{aws_instance_tag}}"
      register: ec2

    - debug: "msg='Started instances {{ ec2.instances }}'"
      when: ec2.instances is defined

    - name: Wait for SSH to come up
      # this doesn't actually mean that you can login to machine
      # TODO: find a way to check when instance is actually ready and health checks passed
      wait_for: host={{ item.public_dns_name }} port=22 delay=60 timeout=320 state=started
      with_items: '{{ ec2.instances }}'
      when: ec2.instances is defined

    - name: Add all instance public IPs to host group
      add_host: hostname={{ item.public_ip }} groups=ec2hosts
      with_items: '{{ ec2.instances }}'
      when: ec2.instances is defined



#####################################################
### Playbook contains tasks for stopping or termintaing instances
#####################################################
- name: STOP/TERM
  hosts: localhost
  connection: local
  gather_facts: false 
  tasks:
    - name: Stop the sandbox instances
      tags: stop
      ec2:
        group: '{{ aws_security_group }}'
        region: '{{ aws_default_region }}'
        key_name: "{{ aws_key_name }}"
        instance_ids: "{{ running_inst }}"
        state: stopped
        wait: True

    - name: Terminate instances
      tags: term
      ec2:
        region: '{{ aws_default_region }}'
        group: '{{ aws_security_group }}'
        instance_ids: "{{ ec2_info.instances|map(attribute='id')|list }}"
        # instance_tags: 
          # Name: "{{aws_instance_tag}}"
        state: absent

    - name: Terminate only stopped instances
      tags: term_stopped
      ec2:
        region: '{{ aws_default_region }}'
        group: '{{ aws_security_group }}'
        instance_ids: "{{ stopped_inst }}"
        state: absent


#####################################################
### Playbook contains tasks to perform health checks 
### on the system
#####################################################
- name: HEALTH CHECK
  hosts: ec2
  tags: check
  remote_user: "{{aws_ec2_user}}"
  become: true
  gather_facts: false 
  tasks:
    - shell: hostname

#####################################################
### Playbook contains tasks to retrive status instead 
### of using aws console
#####################################################
#TODO: play for getting status about running instances
- name: HEALTH CHECK
  hosts: localhost
  tags: status
  # remote_user: "{{aws_ec2_user}}"
  # become: true
  gather_facts: false 
  tasks:
    - set_fact:
        ec2_status: "{{ ec2_status|default([])|union([dict(dns=item.public_dns_name,id=item.id, state=item.state)]) }}"
      with_items: "{{ec2_info.instances}}"
    # - debug: 
    #     var: 
    #       "{{item.id}}": "{{item}}"
    #   with_items: "{{ec2_status}}"
    - debug: msg="{{ec2_status}}"
